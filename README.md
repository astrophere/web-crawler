# web-crawler

A project of a web crawler which will go through all the links linked on a website, then links in those linked websites and so on.

- using STD library
- using std::thread for multithreading

1. Setup project with Github and Sourcetree.
2. Figure out libcurl.
3. HTML link extractor.
4. Make a loop for going through links.
5. Make it multithreaded.
